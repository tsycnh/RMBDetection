## 实验记录：
2019年7月20日：step2-1  
首次搭建基于InceptionV3主干的模型。后接一个256输出的Dense（relu）和9输出的Dense（softmax）  
没有用任何数据增强，没有采用Dropout或BatchNorm。训练10个轮次。  
前3个轮次准确率都没有超过70%，收敛较慢，验证集准确率10%，有明显过拟合的问题。  

2019年7月20日：step2-2  
将学习速率从之前默认的1e-3降低到1e-4。同时在Flatten层后增加Dropout层。
降低学习速率有奇效，模型快速收敛到训练集97.78%，但验证集准确率仅12.39%，严重过拟合,三个轮次后训练集99.94%，验证集16.34%
依然严重过拟合，下一步就是解决过拟合问题  

2019年7月20日：step2-3  
将Dropout层更改到两个Dense层之间。但没有任何效果。

2019年7月20日：step2-4
将输入图像归一化到0~1之间，其他和上次实验不变。  
第一轮次训练集98.54%，验证集81.77%。效果不错。说明之前忘记归一化对模型影响很大。  
第二轮次训练集99.90%，验证集49.33%。  
第三轮次训练集99.94%，验证集87.35%。  
模型中间有些过拟合，最终还有上升空间。

2019年7月20日：step2-5  
增加数据增强，旋转20度。左右平移10%，上下平移10%
第一轮次训练集95.23%，验证集82.87%。  
第二轮次训练集99.55%，验证集84.83%。  
第三轮次训练集99.73%，验证集80.13%。  
整体上有一定效果，但是不明显，过拟合不严重。

2019年7月20日：step2-6  
在step2-4的基础上将Dropout改为0.25
第一轮次训练集98.71%，验证集78.19%。不太行。 

2019年7月20日：step2-7  
在step2-4的基础上将第一个Dense层改为128节点  
第一轮次训练集94.98%，验证集91.71%。  
第二轮次训练集99.21%，验证集92.52%。 
效果优化很明显，不再过拟合。分析原因是之前节点多，导致网络拟合能力过强，导致过拟合。  
第二轮次验证集上升较少，仍有部分过拟合。继续尝试改网络或微调网络



