## 实验记录：
#### Part1：面值分类问题
2019年7月20日：step2-1  
首次搭建基于InceptionV3主干的模型。后接一个256输出的Dense（relu）和9输出的Dense（softmax）  
没有用任何数据增强，没有采用Dropout或BatchNorm。训练10个轮次。  
前3个轮次准确率都没有超过70%，收敛较慢，验证集准确率10%，有明显过拟合的问题。  

2019年7月20日：step2-2  
将学习速率从之前默认的1e-3降低到1e-4。同时在Flatten层后增加Dropout层。
降低学习速率有奇效，模型快速收敛到训练集97.78%，但验证集准确率仅12.39%，严重过拟合,三个轮次后训练集99.94%，验证集16.34%
依然严重过拟合，下一步就是解决过拟合问题  

2019年7月20日：step2-3  
将Dropout层更改到两个Dense层之间。但没有任何效果。

2019年7月20日：step2-4
将输入图像归一化到0~1之间，其他和上次实验不变。  
第一轮次训练集98.54%，验证集81.77%。效果不错。说明之前忘记归一化对模型影响很大。  
第二轮次训练集99.90%，验证集49.33%。  
第三轮次训练集99.94%，验证集87.35%。  
模型中间有些过拟合，最终还有上升空间。

2019年7月20日：step2-5  
增加数据增强，旋转20度。左右平移10%，上下平移10%
第一轮次训练集95.23%，验证集82.87%。  
第二轮次训练集99.55%，验证集84.83%。  
第三轮次训练集99.73%，验证集80.13%。  
整体上有一定效果，但是不明显，过拟合不严重。

2019年7月20日：step2-6  
在step2-4的基础上将Dropout改为0.25
第一轮次训练集98.71%，验证集78.19%。不太行。 

2019年7月20日：step2-7  
在step2-4的基础上将第一个Dense层改为128节点  
第一轮次训练集94.98%，验证集91.71%。  
第二轮次训练集99.21%，验证集92.52%。  
效果优化很明显，不再过拟合。分析原因是之前节点多，导致网络拟合能力过强，导致过拟合。  
第二轮次验证集上升较少，仍有部分过拟合。继续尝试改网络或微调网络

2019年7月21日：step2-8  
在step2-7的基础上，在主干网落后增加一个卷积层和全局池化。带来的效果是参数量显著变少。  
第一轮次训练集84.57%，验证集42.44%。出现过拟合，有待继续观察，会不会Drop的太多了？而且上了Dropout层
之后训练速度明显变慢，看来Dropout有减速的嫌疑。  
第二轮次训练集98.54%，验证集62.13%。 还是过拟合 
第二轮次训练集99.06%，验证集69.86%。  

2019年7月21日：step2-9  
在step2-8基础上移除Dropout层。评估不用归一化方法的效果。
第一轮次训练集93.51%，验证集62.99%。比之前用Dropout强。但是总感觉用的数据是不是有点多？  
第二轮次训练集99.24%，验证集65.15%。

2019年7月21日 14:51:53：step2-10  
用tools/splitdataset.py将图像数据集缩小，每个类别各拿100张出来，再试试。
这次把epoch数量抬上去。依旧按照step2-9参数来训练一遍  
从第五各轮次开始过拟合，最高验证集准确率37% 

2019年7月21日 14:58:13：step2-11  
增加Dropout，验证集最高50%，然后开始过拟合

2019年7月21日 15:03:32：step2-12  
改为2-7模型，保留数据增强  
验证集最高91.78%，但训练不稳定，后面还是会出现过拟合。但效果和2-7基本保持一致。

2019年7月21日 15:18:36：step2-13  
在2-12基础上增加一个密集连接层，并配合以0.5的Dropout率  
惊喜的是，没有出现过拟合，可以继续训练或改为网络微调
轮次：15 训练集：94.67% 验证集：92.67%【BEST*】     

2019年7月21日 15:54:23：step2-14
继续降低学习率为1e-5训练，但是效果并不好。

2019年7月21日 15:54:52：step2-15  
在2-13的基础上继续以1e-4训练20个轮次

2019年7月21日 17:17:35：step2-16  
按step2-13训练100个epoch
epoch：49 训练集：98.11%    验证集：94.67%【BEST】   

2019年7月21日 17:47:11：step3-1  
开始在step2-16模型的基础上进行微调，将最后一个inception模块进行微调，即mixed9之后的层。  
效果奇好，上来直接valacc就干到100%。   

**至此，面值分类问题搞完，结果存在test_result.csv上，Tinymind提交结果为100** 
#### Part2：编码目标检测问题

2019年7月27日 15:40:29：step5-1  
训练第一个模型，按lr 1e-4.10个轮次达到 trainloss 0.4975。继续降低lr

2019年7月27日 15:58:19：step5-2  
采用阶梯学习率，然并卵。最低依旧0.49.写个结果可视化看看训练集预测效果。  
2019年7月27日 16:58:17：visual_detection 
可视化写好了，发现不管什么图像，预测框的位置都差不多，和真实目标框位置相差甚远。但是预测目标框的大小还算不错。也就是说位置预测不准，尺寸预测较准。
可以说网络死了。 

2019年7月27日 16:59:18：step5-3  
将学习率重调为1e-3，跑30个epoch。  
结果是loss稳定在3.9。根本没有收敛的意思  
继续按yolo思路改。

2019年7月29日 09:55:13：step5-4  
改完了loss，继续训练yolo款编码检测器,效果不好，输出全为0

2019年7月29日 13:40:23：step5-5  
加入了Dropout和LeakyReLU，网络开始收敛。trainloss达到1以下
然而是假收敛。输出全为0

2019年7月29日 15:20:40：step5-6  
先训练，然后微调。训练集终于收敛。检测的grid完全没有问题，但是目标框还是有偏移

2019年7月29日 15:46:19：step5-7  
在step5-6基础上，继续训练50个轮次，loss和valloss持续下降，并且有继续下降的趋势。
预测框比之前准确许多，但是还是偏小，中心位置偏左上。

2019年7月29日 15:53:12：step5-8  
在step5-7的基础上继续微调，学习率改为1e-5,学习50轮次。
最终下降到trainloss 0.07 loss和valloss持续下降 0.8。感觉有点慢，学习率太小了

2019年7月29日 16:06:04：step5-9  
在step5-7的基础上按照学习率1e-4微调，学习100轮次
loss 0.07 valloss 0.19  总体来说已经相当不错，训练集和测试集都很准
但是还是有一点坐标不精准，还有改进空间。

2019年7月29日 16:42:09：step5-10  
在step5-9的基础上继续微调，学习100轮次，学习率1e-4
效果非常好，IOU已经非常小了，继续再练练

2019年7月29日 17:11:30：step5-11  
在step5-10的基础上继续学300个轮次，压榨一下极限性能
在170epoch的时候，valloss达到了0.07.trainloss在后期基本维持在0.04
验证集精度很高，IOU基本为1 。已经不用再继续训练了。后期实际切割的时候注意切割大一点范围，不然容易靠边的数字切不全。  
几次训练的loss图：  
![loss](./resource/loss.png)    
部分val集结果，绿色为真值，蓝色为预测值：  
![0.1](./resource/0.1.png)    
![0.2](./resource/0.2.png)    
![100](./resource/100.png)    


**至此，编码的目标检测任务完成，开始搞识别。**

### Part3：编码识别
2019年7月30日 17:39:44：准备识别数据  
用Part2的模型来切割一样实验用样本。切割的样本中存在割不全的情况  
2019年7月30日 21:59:23  
观察了一些目标检测结果后，发现问题可能出在了

2019年7月31日 08:17:40  
继续解冻到activation_43层，按照1e-5学习率训练。虽然loss有降，但valloss上涨，出现过拟合。  